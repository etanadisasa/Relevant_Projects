---
title: "KNN Exercise"
author: "Etana Disasa"
date: "9/16/2019"
output:
  html_document:
    df_print: paged
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)
library(class)
library(reshape)
library(Rfast)
library(caret)
library(dplyr)
```

### Acquiring Data and Exploration
```{r}
MyCleveland <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data", header = FALSE)
colnames(MyCleveland) <- make.names(c("Age","Sex","CP","Trestbps","Chol","Fbs","Restecg","Thalach","Exang", "Oldpeak", "Slope", "Ca", "Thal", "Num"))
#MyCleveland$Ca <- as.numeric(MyCleveland$Ca)
#MyCleveland$Thal <- as.numeric(MyCleveland$Thal)
str(MyCleveland)

```

### Divide the Data into (8:2) Ratio

```{r}
set.seed(19) # For academic purposes when using a pseudorandom function
MyCleveland$Set <- sample(c("training", "test"), nrow(MyCleveland), replace = TRUE, prob = c(0.8, 0.2)) 
head(MyCleveland$Set, n = 40)
head(MyCleveland, n = 5)
str(MyCleveland)
```

```{r}
MyClevelandTraining <- subset(MyCleveland, Set == "training", select = 1 : 11) # I only used the first 11 variables. 
MyClevelandTest <- subset(MyCleveland, Set == "test", select = 1 : 11)
nrow(MyClevelandTraining) + nrow(MyClevelandTest) # Should be 303
head(MyClevelandTraining, n = 5)
```
### KNN with K = 1
```{r}
MyPrediction1 <- class::knn(MyClevelandTraining, MyClevelandTest, cl = MyClevelandTraining$Sex, k =1) 
MyActual1 <- MyClevelandTest$Sex
MyConfusionMatrix1 <- table(MyActual1, MyPrediction1)
MyConfusionMatrix1
```

### Different Values of K 
#### K=3
```{r}
MyPrediction2 <- class::knn(MyClevelandTraining, MyClevelandTest, cl = MyClevelandTraining$Sex, k = 3) 
MyActual2 <- MyClevelandTest$Sex
MyConfusionMatrix2 <- table(MyActual2, MyPrediction2)
MyConfusionMatrix2
```

#### K=5
```{r}
MyPrediction3 <- class::knn(MyClevelandTraining, MyClevelandTest, cl = MyClevelandTraining$Sex, k = 5) 
MyActual3 <- MyClevelandTest$Sex
MyConfusionMatrix3 <- table(MyActual3, MyPrediction3)
MyConfusionMatrix3
```

#### K=7
```{r}
MyPrediction4 <- class::knn(MyClevelandTraining, MyClevelandTest, cl = MyClevelandTraining$Sex, k = 7) 
MyActual4 <- MyClevelandTest$Sex
MyConfusionMatrix4 <- table(MyActual4, MyPrediction4)
MyConfusionMatrix4
```

#### K=9
```{r}
MyPrediction5 <- class::knn(MyClevelandTraining, MyClevelandTest, cl = MyClevelandTraining$Sex, k = 8) 
MyActual5 <- MyClevelandTest$Sex
MyConfusionMatrix5 <- table(MyActual5, MyPrediction5)
MyConfusionMatrix5
```

### Report Error Rate  

```{r}
MyErrorRate1 <- ((MyConfusionMatrix1[1,2] + MyConfusionMatrix1[2,1])/nrow(MyClevelandTest))
MyErrorRate2 <- ((MyConfusionMatrix2[1,2] + MyConfusionMatrix2[2,1])/nrow(MyClevelandTest))
MyErrorRate3 <- ((MyConfusionMatrix3[1,2] + MyConfusionMatrix3[2,1])/nrow(MyClevelandTest))
MyErrorRate4 <- ((MyConfusionMatrix4[1,2] + MyConfusionMatrix4[2,1])/nrow(MyClevelandTest))
MyErrorRate5 <- ((MyConfusionMatrix5[1,2] + MyConfusionMatrix5[2,1])/nrow(MyClevelandTest))
MyError <- data.frame(KValue=c("1","3","5","7","9"),
                      ErrorRate=c(MyErrorRate1,MyErrorRate2,MyErrorRate3,MyErrorRate4,MyErrorRate5)
                      )
MyError # I wanted MyError to be a dataframe so I can use ggplot. 
```

When k=1, our error rate was `r MyErrorRate1 * 100`%. then with k=3 and k=5, the rate moved down to `r MyErrorRate2 * 100`% and `r MyErrorRate3 * 100`%. When k=7 the error rate continued to slightly decrease to `r MyErrorRate4 * 100`% but went up again to `r MyErrorRate5 * 100`% when k=9. Below is a plot to show what happened. 

### Plotting the Error Rates
```{r}
ggplot(MyError, aes(x=KValue, y=ErrorRate)) +
    labs(x= "K Value", y="Error Rate", title = "Error Rates with Change in K") +
    geom_point() +
    geom_segment(aes(x=KValue, xend=KValue, y=ErrorRate, yend=0))
```

# Conclusion
For this exercise, k=7 was the optimal value producing the smallest error rate. 

# References
https://ggplot2.tidyverse.org/reference/labs.html